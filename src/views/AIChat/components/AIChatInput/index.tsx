/**
 * AIChatInput - è¾“å…¥åŒºåŸŸç»„ä»¶
 * ä½¿ç”¨ Ant Design X Sender ç»„ä»¶
 * åŒ…å«å·¥å…·æ ã€è¾“å…¥æ¡†ã€å‘é€æŒ‰é’®ã€çŸ¥è¯†åº“é€‰æ‹©å™¨ã€è¯­éŸ³è¾“å…¥
 * æ”¯æŒç²˜è´´æ–‡ä»¶ã€URL æ£€æµ‹ã€'/' å¿«æ·é€‰æ‹©çŸ¥è¯†åº“
 */
import React, {
  memo,
  useCallback,
  useState,
  useRef,
  useEffect,
  useMemo,
} from "react";
import { Select, Switch, Tooltip, message } from "antd";
import { Sender } from "@ant-design/x";
import type {
  ModelConfig,
  KnowledgeInfo,
  KnowledgeDocumentInfo,
} from "@/types/electron";
import { ConnectionState } from "@/types/electron";
import type { StreamState } from "../../config";
import { useSpeechCapability } from "@/hooks/useSpeechCapability";
import KnowledgeSuggestion from "../KnowledgeSuggestion";

// SpeechRecognition ç±»å‹å®šä¹‰
// eslint-disable-next-line @typescript-eslint/no-explicit-any
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface AIChatInputProps {
  inputValue: string;
  onInputChange: (value: string) => void;
  currentModel: ModelConfig | null;
  connectionState: ConnectionState;
  streamState: StreamState;
  agentMode: boolean;
  onAgentModeChange: (checked: boolean) => void;
  onSend: () => void;
  onCancel?: () => void;
  // çŸ¥è¯†åº“ç›¸å…³
  knowledgeList: KnowledgeInfo[];
  selectedKnowledgeId: string | null;
  onKnowledgeChange: (knowledgeId: string | null) => void;
  // çŸ¥è¯†åº“æ–‡æ¡£æ˜ å°„ï¼ˆç”¨äº '/' å¿«æ·é€‰æ‹©ï¼‰
  knowledgeDocuments?: Record<string, KnowledgeDocumentInfo[]>;
  // é™„ä»¶ç›¸å…³
  onPasteFile?: (file: {
    path: string;
    name: string;
    size: number;
    mimeType: string;
  }) => void;
  onPasteImage?: (file: {
    path: string;
    name: string;
    size: number;
    mimeType: string;
    thumbnail?: string;
  }) => void;
  onDetectUrl?: (url: string) => void;
  // å¿«æ·é€‰æ‹©çŸ¥è¯†åº“å›è°ƒ
  onSelectKnowledgeQuick?: (knowledgeId: string, knowledgeName: string) => void;
  onSelectDocumentQuick?: (
    knowledgeId: string,
    documentId: string,
    documentName: string
  ) => void;
}

const AIChatInput: React.FC<AIChatInputProps> = memo(
  ({
    inputValue,
    onInputChange,
    currentModel,
    connectionState,
    streamState,
    agentMode,
    onAgentModeChange,
    onSend,
    onCancel,
    knowledgeList,
    selectedKnowledgeId,
    onKnowledgeChange,
    knowledgeDocuments = {},
    onPasteFile,
    onPasteImage,
    onDetectUrl,
    onSelectKnowledgeQuick,
    onSelectDocumentQuick,
  }) => {
    // åˆ¤æ–­æ˜¯å¦å¯ä»¥å‘é€
    const canSend =
      inputValue.trim() &&
      connectionState === ConnectionState.CONNECTED &&
      streamState.status !== "streaming" &&
      currentModel;

    // æ˜¯å¦å¤„äºåŠ è½½/æµå¼çŠ¶æ€
    const isLoading = streamState.status === "streaming";

    // æ˜¯å¦ç¦ç”¨è¾“å…¥
    const isDisabled =
      connectionState !== ConnectionState.CONNECTED || isLoading;

    // è¯­éŸ³èƒ½åŠ›æ£€æµ‹
    const speechCapability = useSpeechCapability();

    // å½•éŸ³çŠ¶æ€
    const [isRecording, setIsRecording] = useState(false);

    // SpeechRecognition å®ä¾‹
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const recognitionRef = useRef<any>(null);

    // æ‰“å°è¯­éŸ³èƒ½åŠ›çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
    useEffect(() => {
      console.log("[AIChatInput] è¯­éŸ³èƒ½åŠ›:", {
        isSupported: speechCapability.isSupported,
        hasPermission: speechCapability.hasPermission,
        error: speechCapability.error,
      });
    }, [
      speechCapability.isSupported,
      speechCapability.hasPermission,
      speechCapability.error,
    ]);

    // åˆå§‹åŒ– SpeechRecognition
    useEffect(() => {
      if (!speechCapability.isSupported) return;

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const win = window as any;
      const SpeechRecognition =
        win.SpeechRecognition || win.webkitSpeechRecognition;

      if (SpeechRecognition) {
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = true;
        recognition.lang = "zh-CN";

        recognition.onresult = (event: SpeechRecognitionEvent) => {
          let transcript = "";
          for (let i = 0; i < event.results.length; i++) {
            transcript += event.results[i][0].transcript;
          }
          console.log("[AIChatInput] è¯­éŸ³è¯†åˆ«ç»“æœ:", transcript);
          onInputChange(transcript);
        };

        recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
          console.error(
            "[AIChatInput] è¯­éŸ³è¯†åˆ«é”™è¯¯:",
            event.error,
            event.message
          );
          setIsRecording(false);
          if (event.error === "not-allowed") {
            message.error("éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£");
          } else if (event.error === "no-speech") {
            message.warning("æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•");
          } else {
            message.error(`è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`);
          }
        };

        recognition.onend = () => {
          console.log("[AIChatInput] è¯­éŸ³è¯†åˆ«ç»“æŸ");
          setIsRecording(false);
        };

        recognitionRef.current = recognition;
      }

      return () => {
        if (recognitionRef.current) {
          try {
            recognitionRef.current.stop();
          } catch {
            // å¿½ç•¥åœæ­¢é”™è¯¯
          }
        }
      };
    }, [speechCapability.isSupported, onInputChange]);

    // å¤„ç†å½•éŸ³çŠ¶æ€å˜åŒ–
    const handleRecordingChange = useCallback(
      async (recording: boolean) => {
        console.log("[AIChatInput] å½•éŸ³çŠ¶æ€å˜åŒ–:", recording);

        if (recording) {
          // å¼€å§‹å½•éŸ³å‰å…ˆè¯·æ±‚æƒé™
          if (speechCapability.hasPermission === false) {
            const granted = await speechCapability.requestPermission();
            if (!granted) {
              message.error("æ— æ³•è·å–éº¦å…‹é£æƒé™");
              return;
            }
          }

          // å¼€å§‹è¯­éŸ³è¯†åˆ«
          if (recognitionRef.current) {
            try {
              console.log("[AIChatInput] å¼€å§‹è¯­éŸ³è¯†åˆ«...");
              recognitionRef.current.start();
              setIsRecording(true);
            } catch (err) {
              console.error("[AIChatInput] å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:", err);
              message.error("å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥");
            }
          }
        } else {
          // åœæ­¢è¯­éŸ³è¯†åˆ«
          if (recognitionRef.current) {
            try {
              console.log("[AIChatInput] åœæ­¢è¯­éŸ³è¯†åˆ«...");
              recognitionRef.current.stop();
            } catch {
              // å¿½ç•¥åœæ­¢é”™è¯¯
            }
          }
          setIsRecording(false);
        }
      },
      [speechCapability]
    );

    // å¤„ç†æäº¤
    const handleSubmit = useCallback(() => {
      if (canSend) {
        onSend();
      }
    }, [canSend, onSend]);

    // å¤„ç†å–æ¶ˆ
    const handleCancel = useCallback(() => {
      if (onCancel) {
        onCancel();
      }
    }, [onCancel]);

    // å¤„ç†å†…å®¹å˜åŒ–
    // handleChange ç”± handleChangeWithUrlDetection æ›¿ä»£

    // ========== ç²˜è´´æ–‡ä»¶æ£€æµ‹ ==========

    // URL æ­£åˆ™è¡¨è¾¾å¼ï¼ˆç§»åˆ°ç»„ä»¶å¤–éƒ¨é¿å…ä¾èµ–é—®é¢˜ï¼‰
    // å¤„ç†ç²˜è´´äº‹ä»¶
    const handlePaste = useCallback(
      (e: React.ClipboardEvent) => {
        const clipboardData = e.clipboardData;
        if (!clipboardData) return;

        // æ£€æŸ¥æ–‡ä»¶
        const files = clipboardData.files;
        if (files.length > 0) {
          const file = files[0] as File & { path?: string };
          const filePath = file.path; // Electron ä¸­å¯è·å–æœ¬åœ°è·¯å¾„

          if (!filePath) {
            message.warning("æ— æ³•è·å–æ–‡ä»¶è·¯å¾„ï¼Œè¯·ä½¿ç”¨å…¶ä»–æ–¹å¼ä¸Šä¼ ");
            return;
          }

          const mimeType = file.type || "application/octet-stream";
          const isImage = mimeType.startsWith("image/");

          const fileInfo = {
            path: filePath,
            name: file.name,
            size: file.size,
            mimeType,
          };

          if (isImage && onPasteImage) {
            // å›¾ç‰‡ç±»å‹ï¼Œç”Ÿæˆç¼©ç•¥å›¾
            const reader = new FileReader();
            reader.onload = () => {
              onPasteImage({
                ...fileInfo,
                thumbnail: reader.result as string,
              });
            };
            reader.readAsDataURL(file);
          } else if (onPasteFile) {
            onPasteFile(fileInfo);
          }

          e.preventDefault();
          return;
        }
      },
      [onPasteFile, onPasteImage]
    );

    // ========== URL æ£€æµ‹ ==========

    // æ£€æµ‹è¾“å…¥ä¸­çš„ URL
    const detectUrlInInput = useCallback(
      (value: string) => {
        if (!onDetectUrl) return;

        // ç®€å•æ£€æµ‹ï¼šå¦‚æœè¾“å…¥çš„æ˜¯ä¸€ä¸ª URL
        const trimmed = value.trim();
        if (/^https?:\/\/.+/i.test(trimmed)) {
          onDetectUrl(trimmed);
        }
      },
      [onDetectUrl]
    );

    // åŒ…è£… onChange ä»¥æ£€æµ‹ URL
    const handleChangeWithUrlDetection = useCallback(
      (value: string) => {
        onInputChange(value);
        // å»¶è¿Ÿæ£€æµ‹ï¼Œé¿å…é¢‘ç¹è§¦å‘
        setTimeout(() => detectUrlInInput(value), 100);
      },
      [onInputChange, detectUrlInInput]
    );

    // ========== å¿«æ·é€‰æ‹©çŸ¥è¯†åº“ ==========

    // é€‰ä¸­çš„çŸ¥è¯†åº“æ˜¾ç¤º
    const selectedKnowledgeDisplay = useMemo(() => {
      if (!selectedKnowledgeId) return null;
      const kb = knowledgeList.find((k) => k.id === selectedKnowledgeId);
      return kb ? `@${kb.name}` : null;
    }, [selectedKnowledgeId, knowledgeList]);

    // è®¡ç®— allowSpeech é…ç½®
    // ä½¿ç”¨å—æ§æ¨¡å¼ï¼Œæ‰‹åŠ¨å¤„ç†è¯­éŸ³è¯†åˆ«
    const allowSpeechConfig = speechCapability.isSupported
      ? {
          recording: isRecording,
          onRecordingChange: handleRecordingChange,
        }
      : false;

    // å·¥å…·æ å¤´éƒ¨
    const header = (
      <div className="flex items-center justify-between px-2 py-1.5 border-b border-border/50">
        <div className="flex items-center gap-1">
          {/* æ·»åŠ é™„ä»¶æŒ‰é’® */}
          <Tooltip title="æ·»åŠ é™„ä»¶">
            <button
              className="p-2 text-text-tertiary hover:text-primary hover:bg-primary/10 rounded-lg transition-all"
              type="button"
            >
              <span className="material-symbols-outlined text-lg">
                attach_file
              </span>
            </button>
          </Tooltip>

          {/* ä¸Šä¼ å›¾ç‰‡æŒ‰é’® */}
          <Tooltip title="ä¸Šä¼ å›¾ç‰‡">
            <button
              className="p-2 text-text-tertiary hover:text-primary hover:bg-primary/10 rounded-lg transition-all"
              type="button"
            >
              <span className="material-symbols-outlined text-lg">image</span>
            </button>
          </Tooltip>

          <div className="h-4 w-[1px] bg-border mx-1"></div>

          {/* å¿«æ·æ¨¡æ¿æŒ‰é’® */}
          <Tooltip title="å¿«æ·æ¨¡æ¿">
            <button
              className="flex items-center gap-1.5 px-3 py-1.5 text-text-tertiary hover:text-primary hover:bg-primary/10 rounded-lg transition-all text-xs font-medium"
              type="button"
            >
              <span className="material-symbols-outlined text-base">
                temp_preferences_custom
              </span>
              <span>å¿«æ·æ¨¡æ¿</span>
            </button>
          </Tooltip>

          <div className="h-4 w-[1px] bg-border mx-1"></div>

          {/* çŸ¥è¯†åº“é€‰æ‹©å™¨ - ä»…åœ¨ Agent æ¨¡å¼ä¸‹æ˜¾ç¤º */}
          {agentMode && knowledgeList.length > 0 && (
            <Select
              value={selectedKnowledgeId}
              onChange={onKnowledgeChange}
              placeholder="é€‰æ‹©çŸ¥è¯†åº“"
              allowClear
              size="small"
              style={{ minWidth: 150 }}
              options={knowledgeList.map((kb) => ({
                value: kb.id,
                label: `${kb.name} (${kb.documentCount}æ–‡æ¡£)`,
              }))}
            />
          )}

          <div className="h-4 w-[1px] bg-border mx-1"></div>

          {/* Agent æ¨¡å¼å¼€å…³ */}
          <Tooltip
            title={
              agentMode
                ? "Agent æ¨¡å¼ï¼šæ™ºèƒ½ä½“å°†ä½¿ç”¨å·¥å…·å®Œæˆä»»åŠ¡"
                : "æ™®é€šæ¨¡å¼ï¼šç›´æ¥å¯¹è¯"
            }
          >
            <div className="flex items-center gap-2 px-2">
              <Switch
                size="small"
                checked={agentMode}
                onChange={onAgentModeChange}
                checkedChildren="ğŸ¤–"
                unCheckedChildren="ğŸ’¬"
              />
              <span
                className={`text-xs font-medium ${
                  agentMode ? "text-primary" : "text-text-tertiary"
                }`}
              >
                {agentMode ? "Agent" : "å¯¹è¯"}
              </span>
            </div>
          </Tooltip>
        </div>

        {/* å¿«æ·é”®æç¤º */}
        <div className="text-[10px] text-text-tertiary font-medium">
          æŒ‰ Enter å‘é€ï¼ŒShift + Enter æ¢è¡Œ
        </div>
      </div>
    );

    // åº•éƒ¨æç¤º
    const footer = (
      <div className="flex justify-center py-2">
        <div className="flex items-center gap-1.5 text-[11px] text-text-tertiary">
          <span className="material-symbols-outlined text-base">info</span>
          <span>AI å¯èƒ½ä¼šäº§ç”Ÿé”™è¯¯ï¼Œè¯·æ ¸å®é‡è¦ä¿¡æ¯</span>
        </div>
      </div>
    );

    // è°ƒè¯•æ—¥å¿—
    console.log("[AIChatInput] render, knowledgeList:", knowledgeList?.length);

    return (
      <div className="p-6 bg-transparent">
        <div className="max-w-4xl mx-auto">
          <KnowledgeSuggestion
            knowledgeList={knowledgeList}
            knowledgeDocuments={knowledgeDocuments}
            onSelectKnowledge={onSelectKnowledgeQuick}
            onSelectDocument={onSelectDocumentQuick}
          >
            {({ onTrigger, onKeyDown: onSuggestionKeyDown, open }) => {
              // å­˜å‚¨è§¦å‘å‡½æ•°ä¾› onChange ä½¿ç”¨
              const handleInputChange = (value: string) => {
                handleChangeWithUrlDetection(value);
                
                // æ£€æµ‹ '/' è¾“å…¥ï¼Œè§¦å‘ Suggestion
                if (value.endsWith("/") && !open) {
                  onTrigger(value.slice(-1));
                } else if (!value.includes("/") && open) {
                  onTrigger(false); // å…³é—­
                } else if (open && value.includes("/")) {
                  // æ›´æ–°æœç´¢å…³é”®è¯
                  const slashIndex = value.lastIndexOf("/");
                  const keyword = value.slice(slashIndex + 1);
                  onTrigger("/" + keyword);
                }
              };

              return (
                <Sender
                  value={inputValue}
                  onChange={handleInputChange}
                  onSubmit={handleSubmit}
                  onCancel={isLoading ? handleCancel : undefined}
                  onKeyDown={(e) => {
                    onSuggestionKeyDown(e);
                  }}
                  onPaste={handlePaste}
                  loading={isLoading}
                  disabled={isDisabled}
                  placeholder={
                    selectedKnowledgeDisplay
                      ? `é’ˆå¯¹ã€Œ${selectedKnowledgeDisplay}ã€æé—®...`
                      : "åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œè¾“å…¥ / å¿«é€Ÿé€‰æ‹©çŸ¥è¯†åº“"
                  }
                  submitType="enter"
                  autoSize={{ minRows: 3, maxRows: 8 }}
                  header={header}
                  footer={footer}
                  allowSpeech={allowSpeechConfig}
                  className="bg-bg-secondary border border-border rounded-2xl shadow-xl focus-within:border-primary/50 transition-all"
                  classNames={{
                    input: "text-text-primary placeholder:text-text-tertiary",
                  }}
                />
              );
            }}
          </KnowledgeSuggestion>
        </div>
      </div>
    );
  }
);

AIChatInput.displayName = "AIChatInput";

export default AIChatInput;
