"""
Deep Agent å°è£…æ¨¡å—

åŸºäº LangChain Deep Agents SDK å®ç°çš„é«˜çº§æ™ºèƒ½ä½“ã€‚

Deep Agents æä¾›çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. Planning (ä»»åŠ¡è§„åˆ’) - ä½¿ç”¨ write_todos å·¥å…·åˆ†è§£å¤æ‚ä»»åŠ¡
2. Context Management (ä¸Šä¸‹æ–‡ç®¡ç†) - æ–‡ä»¶ç³»ç»Ÿå·¥å…·ç®¡ç†å¤§å‹ä¸Šä¸‹æ–‡
3. Subagent Spawning (å­æ™ºèƒ½ä½“ç”Ÿæˆ) - éš”ç¦»ä¸Šä¸‹æ–‡æ‰§è¡Œå­ä»»åŠ¡
4. Long-term Memory (é•¿æœŸè®°å¿†) - è·¨å¯¹è¯æŒä¹…åŒ–è®°å¿†

æ¶æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Deep Agent Wrapper                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Deep Agents SDK (create_deep_agent)        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ Planning â”‚ â”‚ File Sys â”‚ â”‚Subagents â”‚ â”‚ Memory   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚(todos)   â”‚ â”‚ (context)â”‚ â”‚(isolate) â”‚ â”‚(persist) â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Custom Tools Layer                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Skills  â”‚ â”‚Knowledge â”‚ â”‚   Memory Service     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ (è‡ªå®šä¹‰)  â”‚ â”‚  (RAG)   â”‚ â”‚   (æ‘˜è¦/è®°å¿†)        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import logging
import asyncio
import os
from typing import AsyncIterator, Dict, Any, List, Optional, Callable
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage

from .tools import BaseTool, global_tool_registry
from .state import AgentStep, ToolCall

logger = logging.getLogger(__name__)


# ==================== Deep Agent é…ç½® ====================

DEEP_AGENT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰å¼ºå¤§çš„ä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œèƒ½åŠ›ã€‚

## âš ï¸ æœ€é«˜ä¼˜å…ˆçº§ï¼šçŸ¥è¯†åº“æ£€ç´¢ç»“æœä½¿ç”¨è§„åˆ™

å½“ç”¨æˆ·æ¶ˆæ¯ä¸­åŒ…å« `[çŸ¥è¯†åº“æ£€ç´¢ç»“æœ]` å—æ—¶ï¼Œ**å¿…é¡»**ç›´æ¥åŸºäºè¯¥å†…å®¹å›ç­”é—®é¢˜ï¼š
1. **ç¦æ­¢**è°ƒç”¨ web_searchã€knowledge_search ç­‰å·¥å…·
2. **ç¦æ­¢**è¯´"è®©æˆ‘æœç´¢ä¸€ä¸‹"æˆ–"æˆ‘æ¥æŸ¥è¯¢ä¸€ä¸‹"
3. çŸ¥è¯†åº“æ£€ç´¢ç»“æœå·²ç»åœ¨æ¶ˆæ¯ä¸­ï¼Œç›´æ¥ä½¿ç”¨å³å¯
4. å¦‚æœçŸ¥è¯†åº“å†…å®¹ä¸è¶³ä»¥å›ç­”ï¼Œå¯ä»¥ç”¨ä½ çš„çŸ¥è¯†è¡¥å……ï¼Œå¹¶æ ‡æ³¨"ï¼ˆæ ¹æ®æˆ‘çš„çŸ¥è¯†è¡¥å……ï¼‰"

## âš ï¸ é‡è¦ï¼šå·¥å…·è°ƒç”¨åˆ¤æ–­åŸåˆ™

åœ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ä¹‹å‰ï¼Œè¯·å…ˆåˆ¤æ–­ï¼š

### ä¸éœ€è¦è°ƒç”¨å·¥å…·çš„æƒ…å†µï¼ˆç›´æ¥å›ç­”ï¼‰
1. **æ—¥å¸¸é—®å€™**ï¼šå¦‚"ä½ å¥½"ã€"æ—©ä¸Šå¥½"ã€"è°¢è°¢"ç­‰
2. **å¸¸è¯†é—®é¢˜**ï¼šå¦‚"1+1ç­‰äºå‡ "ã€"å¤©ç©ºæ˜¯ä»€ä¹ˆé¢œè‰²"
3. **åˆ›æ„å†™ä½œ**ï¼šå¦‚"å†™ä¸€é¦–è¯—"ã€"å¸®æˆ‘å†™ä¸ªæ•…äº‹"
4. **ç¿»è¯‘æ¶¦è‰²**ï¼šå¦‚"ç¿»è¯‘è¿™æ®µè¯"ã€"å¸®æˆ‘æ¶¦è‰²æ–‡ç« "
5. **ä»£ç è§£é‡Š**ï¼šå¦‚"è§£é‡Šè¿™æ®µä»£ç çš„ä½œç”¨"
6. **ç®€å•è®¡ç®—**ï¼šå¦‚"è®¡ç®—100çš„å¹³æ–¹æ ¹"
7. **èŠå¤©é—²è°ˆ**ï¼šä¸ç”¨æˆ·è¿›è¡Œçš„æ™®é€šå¯¹è¯
8. **æ¶ˆæ¯ä¸­å·²æœ‰çŸ¥è¯†åº“æ£€ç´¢ç»“æœ**ï¼šç›´æ¥ä½¿ç”¨ï¼Œä¸è¦å†è°ƒç”¨å·¥å…·

### ğŸ”´ å¿…é¡»è°ƒç”¨å·¥å…·çš„æƒ…å†µ

**æ–‡ä»¶åˆ†æï¼ˆä½¿ç”¨ file_readï¼‰** - æœ€é«˜ä¼˜å…ˆçº§ï¼š
- ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶å¹¶è¯¢é—®æ–‡ä»¶å†…å®¹
- ç”¨æˆ·é—®"è¿™ä¸ªæ–‡æ¡£è®²äº†ä»€ä¹ˆ"ã€"æ–‡ä»¶å†…å®¹æ˜¯ä»€ä¹ˆ"
- å½“ç”¨æˆ·æ¶ˆæ¯ä¸­åŒ…å«"[é‡è¦ï¼šç”¨æˆ·ä¸Šä¼ äº†ä»¥ä¸‹æ–‡ä»¶]"æ—¶
- **å¿…é¡»å…ˆè°ƒç”¨ file_read å·¥å…·è¯»å–æ–‡ä»¶å†…å®¹ï¼**
- è°ƒç”¨æ ¼å¼ï¼šfile_read(file_path="æ–‡ä»¶è·¯å¾„")

**çŸ¥è¯†åº“æŸ¥è¯¢ï¼ˆä½¿ç”¨ knowledge_search æˆ– knowledge_listï¼‰** - ä»…å½“æ¶ˆæ¯ä¸­æ²¡æœ‰çŸ¥è¯†åº“æ£€ç´¢ç»“æœæ—¶ï¼š
- ç”¨æˆ·è¯¢é—®è´¦å·ã€å¯†ç ã€é…ç½®ã€æœåŠ¡å™¨ä¿¡æ¯ç­‰å­˜å‚¨çš„èµ„æ–™
- ç”¨æˆ·é—®"æˆ‘çš„xxxæ˜¯ä»€ä¹ˆ"ã€"xxxåœ¨å“ªé‡Œ"
- æ¶‰åŠç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£ã€é¡¹ç›®èµ„æ–™ã€æŠ€æœ¯æ–‡æ¡£
- **æ³¨æ„**ï¼šå¦‚æœæ¶ˆæ¯ä¸­å·²æœ‰ `[çŸ¥è¯†åº“æ£€ç´¢ç»“æœ]`ï¼Œä¸è¦å†è°ƒç”¨æ­¤å·¥å…·

**å…¶ä»–å·¥å…·è°ƒç”¨**ï¼š
- ç½‘ç»œæœç´¢ï¼šéœ€è¦è·å–æœ€æ–°ä¿¡æ¯ã€å®æ—¶æ•°æ®ï¼ˆä¸”æ¶ˆæ¯ä¸­æ²¡æœ‰çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼‰
- ç³»ç»Ÿæ“ä½œï¼šåˆ›å»ºã€åˆ é™¤ã€ä¿®æ”¹æ•°æ®
- å¤æ‚åˆ†æï¼šéœ€è¦å¤šæ­¥éª¤æ¨ç†æˆ–å¤šæ•°æ®æºæ•´åˆ

**åˆ¤æ–­æµç¨‹**ï¼š
1. æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦å·²æœ‰ `[çŸ¥è¯†åº“æ£€ç´¢ç»“æœ]`ï¼Œå¦‚æœæœ‰åˆ™ç›´æ¥ä½¿ç”¨
2. æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸Šä¼ äº†æ–‡ä»¶ï¼ˆæ¶ˆæ¯ä¸­åŒ…å«æ–‡ä»¶è·¯å¾„ï¼‰
3. å¦‚æœæœ‰æ–‡ä»¶ï¼Œ**å¿…é¡»å…ˆè°ƒç”¨ file_read è¯»å–æ–‡ä»¶å†…å®¹**
4. å¦‚æœæ²¡æœ‰æ–‡ä»¶ä½†æ¶‰åŠç”¨æˆ·å­˜å‚¨çš„ä¿¡æ¯ï¼Œè°ƒç”¨ knowledge_search æ£€ç´¢çŸ¥è¯†åº“
5. å¦‚æœæ˜¯æ—¥å¸¸é—®å€™æˆ–å¸¸è¯†é—®é¢˜ï¼Œç›´æ¥å›ç­”
6. æ ¹æ®å·¥å…·ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜

## ğŸ¯ è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼‰

**æœ€ç»ˆå›ç­”å¿…é¡»æ»¡è¶³**ï¼š
- ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€æˆ–è¯´æ˜
- ä¸è¦å†™"æ ¹æ®æ£€ç´¢ç»“æœ"ã€"æ ¹æ®çŸ¥è¯†åº“"ç­‰å¼€åœºç™½
- ä¸è¦æè¿°ä½ æŸ¥çœ‹äº†ä»€ä¹ˆæ–‡æ¡£æˆ–è°ƒç”¨äº†ä»€ä¹ˆå·¥å…·
- ä¸è¦åŒ…å«æŠ€æœ¯ç»†èŠ‚ï¼ˆçŸ¥è¯†åº“IDã€æ–‡ä»¶åã€ç›¸å…³åº¦åˆ†æ•°ç­‰ï¼‰
- ç”¨è‡ªç„¶ã€æµç•…çš„è¯­è¨€ç›´æ¥ç»™å‡ºç­”æ¡ˆ

**é”™è¯¯ç¤ºä¾‹**ï¼š
æ ¹æ®æ£€ç´¢ç»“æœï¼Œè¿™ä¸ªçŸ¥è¯†åº“ä¸»è¦åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
1. Skills æ˜¯...

**æ­£ç¡®ç¤ºä¾‹**ï¼š
è¿™ä¸ªçŸ¥è¯†åº“ä»‹ç»äº† Claude çš„ Skills ç³»ç»Ÿã€‚Skills æ˜¯åŒ…å«æŒ‡ä»¤ã€è„šæœ¬å’Œèµ„æºçš„æ–‡ä»¶å¤¹ï¼ŒClaude å¯ä»¥åŠ¨æ€åŠ è½½æ¥æå‡ç‰¹å®šä»»åŠ¡çš„è¡¨ç°ã€‚

## æ ¸å¿ƒèƒ½åŠ›

### 1. ä»»åŠ¡è§„åˆ’ (Planning)
- ä½¿ç”¨ write_todos å·¥å…·å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯ç®¡ç†çš„æ­¥éª¤
- è·Ÿè¸ªè¿›åº¦å¹¶åŠ¨æ€è°ƒæ•´è®¡åˆ’

### 2. ä¸Šä¸‹æ–‡ç®¡ç† (Context Management)
- ä½¿ç”¨æ–‡ä»¶ç³»ç»Ÿå·¥å…·å­˜å‚¨å’Œæ£€ç´¢å¤§é‡ä¿¡æ¯
- é¿å…ä¸Šä¸‹æ–‡çª—å£æº¢å‡º

### 3. å­ä»»åŠ¡å§”æ´¾ (Subagent Spawning)
- ä½¿ç”¨ task å·¥å…·åˆ›å»ºä¸“é—¨çš„å­æ™ºèƒ½ä½“
- ä¿æŒä¸»ä¸Šä¸‹æ–‡æ¸…æ´

## å·¥ä½œåŸåˆ™

1. **çŸ¥è¯†åº“æ£€ç´¢ç»“æœä¼˜å…ˆ**ï¼šæ¶ˆæ¯ä¸­æœ‰çŸ¥è¯†åº“æ£€ç´¢ç»“æœæ—¶ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸è¦å†è°ƒç”¨å·¥å…·
2. **æ–‡ä»¶åˆ†ææ¬¡ä¼˜å…ˆ**ï¼šç”¨æˆ·ä¸Šä¼ æ–‡ä»¶æ—¶ï¼Œå¿…é¡»å…ˆè¯»å–æ–‡ä»¶å†…å®¹
3. **ç®€å•é—®é¢˜ç›´æ¥å›ç­”**ï¼šæ—¥å¸¸é—®å€™å’Œå¸¸è¯†é—®é¢˜ï¼Œç›´æ¥ç»™å‡ºæ¸…æ™°ã€å‹å¥½çš„å›ç­”
4. **å¤æ‚é—®é¢˜å…ˆè§„åˆ’**ï¼šæ”¶åˆ°å¤æ‚ä»»åŠ¡æ—¶ï¼Œå…ˆè§„åˆ’æ­¥éª¤å†æ‰§è¡Œ
5. **å–„ç”¨å·¥å…·**ï¼šçœŸæ­£éœ€è¦æ—¶æ‰è°ƒç”¨å·¥å…·ï¼Œé¿å…è¿‡åº¦ä½¿ç”¨
6. **ä¿æŒæ¸…æ™°**ï¼šç»™å‡ºæœ€ç»ˆç­”æ¡ˆæ—¶è¦å®Œæ•´ã€æ¸…æ™°

## æ³¨æ„äº‹é¡¹

1. ä¸è¦å¯¹æ‰€æœ‰é—®é¢˜éƒ½è°ƒç”¨å·¥å…·ï¼Œç®€å•é—®å€™ç›´æ¥å›ç­”
2. **æ¶ˆæ¯ä¸­å·²æœ‰çŸ¥è¯†åº“æ£€ç´¢ç»“æœæ—¶ï¼Œç¦æ­¢å†è°ƒç”¨ web_search ç­‰å·¥å…·**
3. **ä½†ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶æ—¶å¿…é¡»å…ˆè°ƒç”¨ file_read è¯»å–æ–‡ä»¶**
4. ä»”ç»†åˆ†æå·¥å…·è¿”å›çš„ç»“æœ
5. å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•æˆ–ç›´æ¥å›ç­”
6. æœ€ç»ˆå›ç­”è¦ç®€æ´ï¼Œä¸è¦è¾“å‡ºå·¥å…·è°ƒç”¨çš„åŸå§‹å†…å®¹
"""


# ==================== æ¶ˆæ¯å‘é€å™¨æ¥å£ ====================

class MessageSender:
    """
    æ¶ˆæ¯å‘é€å™¨æ¥å£

    ç”¨äºåœ¨ Agent æ‰§è¡Œè¿‡ç¨‹ä¸­å‘é€æ­¥éª¤æ¶ˆæ¯åˆ°å‰ç«¯ã€‚
    """

    def __init__(self, send_callback: Optional[Callable] = None):
        """
        åˆå§‹åŒ–æ¶ˆæ¯å‘é€å™¨

        Args:
            send_callback: å‘é€æ¶ˆæ¯çš„å›è°ƒå‡½æ•°
        """
        self.send_callback = send_callback

    async def send_step(
        self,
        conversation_id: str,
        step_type: str,
        content: str,
        tool_call: Optional[Dict] = None,
        iteration: int = 0
    ):
        """
        å‘é€ Agent æ­¥éª¤æ¶ˆæ¯

        Args:
            conversation_id: ä¼šè¯ ID
            step_type: æ­¥éª¤ç±»å‹ (thought/tool_call/tool_result/answer)
            content: æ­¥éª¤å†…å®¹
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            iteration: è¿­ä»£æ¬¡æ•°
        """
        if self.send_callback:
            import time
            # è¿‡æ»¤æ‰ None æˆ–ç©ºå†…å®¹ï¼Œé¿å…å‰ç«¯æ˜¾ç¤º "None"
            safe_content = content if content and content != "None" else ""
            await self.send_callback({
                "type": "agent_step",
                "id": f"agent_step_{int(time.time() * 1000)}_{iteration}",
                "conversationId": conversation_id,
                "stepType": step_type,
                "content": safe_content,
                "toolCall": tool_call,
                "iteration": iteration
            })


# ==================== Deep Agent Wrapper ====================

class DeepAgentWrapper:
    """
    Deep Agent å°è£…ç±»

    å°è£… Deep Agents SDKï¼Œé›†æˆè‡ªå®šä¹‰å·¥å…·å’Œæ¶ˆæ¯å‘é€åŠŸèƒ½ã€‚

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        agent = DeepAgentWrapper(model_id=1)

        # æµå¼æ‰§è¡Œ
        async for step in agent.astream("å¸®æˆ‘åˆ†æè¿™ä¸ªé—®é¢˜", conversation_id="123"):
            print(step)
    """

    # ç±»çº§åˆ«çš„é™„ä»¶è·¯å¾„æ˜ å°„ï¼ˆç”¨äºä¿®æ­£ file_read å·¥å…·çš„è·¯å¾„ï¼‰
    _attachment_paths: Dict[str, str] = {}

    def __init__(
        self,
        model_id: Optional[int] = None,
        tools: Optional[List[BaseTool]] = None,
        system_prompt: Optional[str] = None,
        message_sender: Optional[MessageSender] = None
    ):
        """
        åˆå§‹åŒ– Deep Agent

        Args:
            model_id: æ¨¡å‹é…ç½® ID
            tools: è‡ªå®šä¹‰å·¥å…·åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            message_sender: æ¶ˆæ¯å‘é€å™¨
        """
        self.model_id = model_id
        self.custom_tools = tools or []
        self.system_prompt = system_prompt or DEEP_AGENT_SYSTEM_PROMPT
        self.message_sender = message_sender

        # å»¶è¿Ÿåˆå§‹åŒ– agentï¼ˆåœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶åˆ›å»ºï¼‰
        self._agent = None
        self._model_config = None

    @classmethod
    def set_attachment_paths(cls, paths: Dict[str, str]):
        """
        è®¾ç½®é™„ä»¶è·¯å¾„æ˜ å°„

        Args:
            paths: æ–‡ä»¶å -> æ–‡ä»¶è·¯å¾„ çš„æ˜ å°„å­—å…¸
        """
        cls._attachment_paths = paths
        logger.info(f"[DeepAgent] è®¾ç½®é™„ä»¶è·¯å¾„æ˜ å°„: {paths}")

    @classmethod
    def get_correct_file_path(cls, provided_path: str) -> str:
        """
        è·å–æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„

        å¦‚æœæä¾›çš„è·¯å¾„ä¸åœ¨é™„ä»¶æ˜ å°„ä¸­ï¼Œå°è¯•æŸ¥æ‰¾åŒ¹é…çš„è·¯å¾„ã€‚
        å¦‚æœå®Œå…¨æ‰¾ä¸åˆ°åŒ¹é…ï¼Œåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªé™„ä»¶çš„è·¯å¾„ï¼ˆå…œåº•ç­–ç•¥ï¼‰ã€‚

        Args:
            provided_path: LLM æä¾›çš„æ–‡ä»¶è·¯å¾„

        Returns:
            æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„
        """
        if not cls._attachment_paths:
            return provided_path

        # å¦‚æœè·¯å¾„ç›´æ¥åŒ¹é…
        if provided_path in cls._attachment_paths.values():
            return provided_path

        # å¦‚æœè·¯å¾„åœ¨æ˜ å°„ä¸­ï¼ˆkey æ˜¯æ–‡ä»¶åï¼‰
        if provided_path in cls._attachment_paths:
            return cls._attachment_paths[provided_path]

        # å°è¯•é€šè¿‡æ–‡ä»¶ååŒ¹é…
        provided_name = os.path.basename(provided_path)
        for name, path in cls._attachment_paths.items():
            if name == provided_name or os.path.basename(path) == provided_name:
                logger.info(f"[DeepAgent] è·¯å¾„ä¿®æ­£: {provided_path} -> {path}")
                return path

        # å…œåº•ç­–ç•¥ï¼šLLM ç¼–é€ çš„è·¯å¾„å®Œå…¨ä¸å¯¹æ—¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé™„ä»¶çš„è·¯å¾„
        first_path = list(cls._attachment_paths.values())[
            0] if cls._attachment_paths else provided_path
        if first_path != provided_path:
            logger.info(
                f"[DeepAgent] è·¯å¾„å…œåº•ä¿®æ­£ï¼ˆLLMç¼–é€ è·¯å¾„ï¼‰: {provided_path} -> {first_path}")
            return first_path

        return provided_path

    def _get_model_config(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹é…ç½®

        Returns:
            æ¨¡å‹é…ç½®å­—å…¸
        """
        from model_router import model_router

        if self._model_config is None:
            if self.model_id:
                self._model_config = model_router.get_config(self.model_id)
            else:
                # è·å–é»˜è®¤æ¨¡å‹ï¼ˆç¬¬ä¸€ä¸ªå·²æ³¨å†Œçš„æ¨¡å‹ï¼‰
                if model_router._models:
                    first_model_id = list(model_router._models.keys())[0]
                    self._model_config = model_router.get_config(
                        first_model_id)

        return self._model_config or {}

    def _build_model_string(self) -> str:
        """
        æ„å»º Deep Agents æ¨¡å‹å­—ç¬¦ä¸²

        Deep Agents ä½¿ç”¨ "provider:model" æ ¼å¼æŒ‡å®šæ¨¡å‹ã€‚

        Returns:
            æ¨¡å‹å­—ç¬¦ä¸²ï¼Œå¦‚ "openai:gpt-4" æˆ– "anthropic:claude-3-sonnet"
        """
        config = self._get_model_config()
        if not config:
            return "openai:gpt-4"  # é»˜è®¤æ¨¡å‹

        # ModelConfig æ˜¯å¯¹è±¡ï¼Œéœ€è¦ä½¿ç”¨å±æ€§è®¿é—®
        provider = ""
        model_id = ""

        if hasattr(config, 'provider'):
            provider = config.provider.value if hasattr(
                config.provider, 'value') else str(config.provider)
            model_id = config.model_id
        else:
            # å…¼å®¹å­—å…¸æ ¼å¼
            provider = config.get("provider", "")
            model_id = config.get("model_id", "")

        provider = provider.lower() if provider else ""

        # æ˜ å°„ provider åç§°åˆ° Deep Agents æ ¼å¼
        provider_map = {
            "openai": "openai",
            "anthropic": "anthropic",
            "azure": "azure_openai",
            "google": "google_genai",
            "ollama": "ollama",  # éœ€è¦ç‰¹æ®Šå¤„ç†
            "bailian": "openai",  # ç™¾ç‚¼ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
            "zhipu": "openai",  # æ™ºè°±ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        }

        mapped_provider = provider_map.get(provider, "openai")

        # å¯¹äº Ollama å’Œå…¶ä»–æœ¬åœ°æ¨¡å‹ï¼Œä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼
        if provider in ["ollama", "bailian", "zhipu"]:
            # è¿™äº›ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            return f"openai:{model_id}"

        return f"{mapped_provider}:{model_id}"

    def _create_chat_model(self):
        """
        åˆ›å»º LangChain ChatModel å®ä¾‹

        æ ¹æ® Deep Agents SDK æ–‡æ¡£ï¼Œä½¿ç”¨ init_chat_model åˆ›å»ºæ¨¡å‹ï¼Œ
        æ”¯æŒè‡ªå®šä¹‰ API base URL ç­‰é…ç½®ã€‚

        Returns:
            LangChain ChatModel å®ä¾‹
        """
        from langchain.chat_models import init_chat_model

        config = self._get_model_config()
        if not config:
            # é»˜è®¤ä½¿ç”¨ OpenAI
            return init_chat_model("gpt-4")

        # æå–é…ç½®
        if hasattr(config, 'provider'):
            provider = config.provider.value if hasattr(
                config.provider, 'value') else str(config.provider)
            model_id = config.model_id
            api_key = config.api_key
            api_base_url = config.api_base_url
            temperature = config.temperature
            max_tokens = config.max_tokens
        else:
            # å…¼å®¹å­—å…¸æ ¼å¼
            provider = config.get("provider", "openai")
            model_id = config.get("model_id", "gpt-4")
            api_key = config.get("api_key")
            api_base_url = config.get("api_base_url")
            temperature = config.get("temperature", 0.7)
            max_tokens = config.get("max_tokens", 4096)

        provider = provider.lower() if provider else "openai"

        # æ„å»ºæ¨¡å‹ kwargs
        model_kwargs = {"temperature": temperature}
        if max_tokens:
            model_kwargs["max_tokens"] = max_tokens

        # å¯¹äº OpenAI å…¼å®¹æ¥å£ï¼ˆç™¾ç‚¼ã€æ™ºè°±ã€Ollama ç­‰ï¼‰ï¼Œä½¿ç”¨ openai provider
        # å¹¶ä¼ é€’è‡ªå®šä¹‰ base_url
        if provider in ["ollama", "bailian", "zhipu"]:
            # è¿™äº›ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
            if api_key:
                model_kwargs["api_key"] = api_key
            if api_base_url:
                model_kwargs["base_url"] = api_base_url

            logger.info(
                f"[DeepAgent] åˆ›å»º ChatModel, provider=openai (å…¼å®¹), model={model_id}, base_url={api_base_url}")

            return init_chat_model(
                model_id,
                model_provider="openai",
                **model_kwargs
            )

        # å…¶ä»– provider
        if api_key:
            model_kwargs["api_key"] = api_key
        if api_base_url and provider == "openai":
            model_kwargs["base_url"] = api_base_url

        # æ˜ å°„ provider åç§°
        provider_map = {
            "openai": "openai",
            "anthropic": "anthropic",
            "azure": "azure_openai",
            "google": "google_genai",
        }
        mapped_provider = provider_map.get(provider, provider)

        logger.info(
            f"[DeepAgent] åˆ›å»º ChatModel, provider={mapped_provider}, model={model_id}")

        return init_chat_model(
            model_id,
            model_provider=mapped_provider,
            **model_kwargs
        )

    def _create_agent(self):
        """
        åˆ›å»º Deep Agent å®ä¾‹

        ä½¿ç”¨ Deep Agents SDK åˆ›å»ºæ™ºèƒ½ä½“ã€‚
        """
        try:
            from deepagents import create_deep_agent
            from langchain_core.tools import StructuredTool

            # è½¬æ¢å·¥å…·ä¸º LangChain StructuredTool åˆ—è¡¨
            # ä½¿ç”¨ StructuredTool ç¡®ä¿å‚æ•° schema æ­£ç¡®ä¼ é€’ç»™ LLM
            langchain_tools = []
            for tool in self.custom_tools:
                # å°† BaseTool è½¬æ¢ä¸º LangChain StructuredTool
                lc_tool = self._convert_to_langchain_tool(tool)
                if lc_tool:
                    langchain_tools.append(lc_tool)

            # åˆ›å»º ChatModel å®ä¾‹ï¼ˆè€Œéå­—ç¬¦ä¸²ï¼‰ï¼Œæ”¯æŒè‡ªå®šä¹‰ API é…ç½®
            chat_model = self._create_chat_model()

            logger.info(
                f"[DeepAgent] åˆ›å»º Agentï¼Œæ¨¡å‹ç±»å‹: {type(chat_model).__name__}, å·¥å…·æ•°é‡: {len(langchain_tools)}")

            # åˆ›å»º Deep Agent
            agent = create_deep_agent(
                model=chat_model,  # ä¼ é€’ ChatModel å®ä¾‹è€Œéå­—ç¬¦ä¸²
                tools=langchain_tools,
                system_prompt=self.system_prompt
            )

            return agent

        except ImportError as e:
            logger.warning(
                f"[DeepAgent] Deep Agents SDK æœªå®‰è£…ï¼Œé™çº§åˆ° ReAct Agent: {e}")
            return None
        except Exception as e:
            logger.error(f"[DeepAgent] åˆ›å»º Agent å¤±è´¥: {e}")
            return None

    def _convert_to_langchain_tool(self, tool: "BaseTool"):
        """
        å°† BaseTool è½¬æ¢ä¸º LangChain StructuredTool

        ç¡®ä¿å‚æ•° schema æ­£ç¡®ä¼ é€’ç»™ LLMï¼Œè®© LLM çŸ¥é“å¦‚ä½•è°ƒç”¨å·¥å…·ã€‚
        """
        from langchain_core.tools import StructuredTool
        import asyncio

        tool_name = tool.name
        tool_description = tool.description
        args_schema = tool.args_schema

        # åˆ›å»ºå¼‚æ­¥åŒ…è£…å‡½æ•°
        async def async_tool_wrapper(**kwargs):
            # å¦‚æœæ˜¯ file_read å·¥å…·ï¼Œä¿®æ­£æ–‡ä»¶è·¯å¾„
            if tool_name == "file_read" and "file_path" in kwargs:
                original_path = kwargs["file_path"]
                corrected_path = DeepAgentWrapper.get_correct_file_path(
                    original_path)
                if corrected_path != original_path:
                    logger.info(
                        f"[DeepAgent] æ–‡ä»¶è·¯å¾„ä¿®æ­£: {original_path} -> {corrected_path}")
                    kwargs["file_path"] = corrected_path

            logger.info(f"[DeepAgent] å¼‚æ­¥è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {kwargs}")

            try:
                # å¦‚æœå·¥å…·æœ‰å¼‚æ­¥æ‰§è¡Œæ–¹æ³•ï¼Œä½¿ç”¨å¼‚æ­¥æ–¹æ³•
                # FrontendBridgeTool ä½¿ç”¨ _call_async
                if hasattr(tool, '_call_async'):
                    logger.info(f"[DeepAgent] ä½¿ç”¨ _call_async: {tool_name}")
                    result = await tool._call_async(**kwargs)
                    logger.info(f"[DeepAgent] å·¥å…·å®Œæˆ: {tool_name}")
                    return result
                # KnowledgeListTool ä½¿ç”¨ _list_via_bridge
                elif hasattr(tool, '_list_via_bridge'):
                    logger.info(
                        f"[DeepAgent] ä½¿ç”¨ _list_via_bridge: {tool_name}")
                    result = await tool._list_via_bridge()
                    # æ ¼å¼åŒ–ç»“æœ
                    if not result:
                        return "å½“å‰æ²¡æœ‰å¯ç”¨çš„çŸ¥è¯†åº“ã€‚è¯·å…ˆåˆ›å»ºçŸ¥è¯†åº“å¹¶ä¸Šä¼ æ–‡æ¡£ã€‚"
                    lines = ["å¯ç”¨çš„çŸ¥è¯†åº“ï¼š\n"]
                    for kb in result:
                        name = kb.get('name', 'æœªå‘½å')
                        kb_id = kb.get('id', 'æœªçŸ¥')
                        doc_count = kb.get('documentCount', 0)
                        desc = kb.get('description', '')
                        lines.append(f"- {name} (ID: {kb_id})")
                        lines.append(f"  æ–‡æ¡£æ•°: {doc_count}")
                        if desc:
                            lines.append(f"  æè¿°: {desc}")
                    logger.info(f"[DeepAgent] å·¥å…·å®Œæˆ: {tool_name}")
                    return "\n".join(lines)
                # FrontendBridgeListTool ä½¿ç”¨ _list_async
                elif hasattr(tool, '_list_async'):
                    logger.info(f"[DeepAgent] ä½¿ç”¨ _list_async: {tool_name}")
                    result = await tool._list_async(kwargs.get('service'))
                    logger.info(f"[DeepAgent] å·¥å…·å®Œæˆ: {tool_name}")
                    return result
                # KnowledgeCreateTool ç­‰ä½¿ç”¨ _create_via_bridge
                elif hasattr(tool, '_create_via_bridge'):
                    logger.info(
                        f"[DeepAgent] ä½¿ç”¨ _create_via_bridge: {tool_name}")
                    result = await tool._create_via_bridge(**kwargs)
                    if result.get("success"):
                        kb = result.get("knowledge", {})
                        logger.info(f"[DeepAgent] å·¥å…·å®Œæˆ: {tool_name}")
                        return (
                            f"çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸï¼\n"
                            f"åç§°: {kb.get('name')}\n"
                            f"ID: {kb.get('id')}\n"
                            f"åµŒå…¥æ¨¡å‹: {kb.get('embeddingModelName')}\n"
                            f"ç°åœ¨å¯ä»¥ä½¿ç”¨ web_crawl å·¥å…·æ·»åŠ å†…å®¹ã€‚"
                        )
                    logger.info(f"[DeepAgent] å·¥å…·å®Œæˆ(å¤±è´¥): {tool_name}")
                    return f"åˆ›å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                else:
                    # åŒæ­¥å·¥å…·ç›´æ¥è¿è¡Œ
                    logger.info(f"[DeepAgent] ä½¿ç”¨åŒæ­¥ run: {tool_name}")
                    result = tool.run(**kwargs)
                    logger.info(f"[DeepAgent] å·¥å…·å®Œæˆ: {tool_name}")
                    return result

            except Exception as e:
                error_msg = f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}"
                logger.error(error_msg)
                return error_msg

        # ä½¿ç”¨ StructuredTool.from_function åˆ›å»ºå·¥å…·
        # è¿™ç¡®ä¿å‚æ•° schema æ­£ç¡®ä¼ é€’ç»™ LLM
        return StructuredTool.from_function(
            coroutine=async_tool_wrapper,  # å¼‚æ­¥å‡½æ•°
            name=tool_name,
            description=tool_description,
            args_schema=args_schema,  # ä¼ é€’å‚æ•° schema
        )

    def _ensure_agent(self):
        """ç¡®ä¿ Agent å·²åˆ›å»º"""
        if self._agent is None:
            self._agent = self._create_agent()

    def run(
        self,
        input_text: str,
        messages: Optional[List] = None,
        conversation_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åŒæ­¥æ‰§è¡Œ Agent

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            messages: å†å²æ¶ˆæ¯åˆ—è¡¨
            conversation_id: ä¼šè¯ ID

        Returns:
            æ‰§è¡Œç»“æœ

        Note:
            å½“ Deep Agents SDK æœªå®‰è£…æ—¶ï¼Œä¸ä¼šè‡ªåŠ¨é™çº§åˆ°æ™®é€š LLM èŠå¤©ï¼Œ
            è€Œæ˜¯æŠ›å‡º ImportErrorï¼Œè®©è°ƒç”¨è€…å†³å®šå¦‚ä½•é™çº§ã€‚
        """
        self._ensure_agent()

        if self._agent is None:
            # Deep Agent ä¸å¯ç”¨ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©è°ƒç”¨è€…å¤„ç†é™çº§
            raise ImportError("Deep Agents SDK æœªå®‰è£…ï¼Œè¯·é™çº§åˆ° ReAct Agent")

        # æ„å»ºæ¶ˆæ¯
        if messages is None:
            messages = [HumanMessage(content=input_text)]

        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        formatted_messages = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                formatted_messages.append(
                    {"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                formatted_messages.append(
                    {"role": "assistant", "content": msg.content})
            else:
                formatted_messages.append(
                    {"role": "user", "content": str(msg.content)})

        try:
            # æ‰§è¡Œ Agent
            result = self._agent.invoke({"messages": formatted_messages})

            # æå–æœ€ç»ˆå“åº”
            final_message = result.get(
                "messages", [])[-1] if result.get("messages") else None

            return {
                "output": final_message.content if final_message else "",
                "steps": self._extract_steps(result),
                "raw_result": result
            }

        except Exception as e:
            logger.error(f"[DeepAgent] æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "output": f"æ‰§è¡Œå‡ºé”™: {str(e)}",
                "error": str(e)
            }

    async def astream(
        self,
        input_text: str,
        messages: Optional[List] = None,
        conversation_id: Optional[str] = None
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        æµå¼æ‰§è¡Œ Agent

        æ¯æ‰§è¡Œä¸€ä¸ªæ­¥éª¤ï¼Œè¿”å›çŠ¶æ€æ›´æ–°ã€‚

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            messages: å†å²æ¶ˆæ¯åˆ—è¡¨
            conversation_id: ä¼šè¯ ID

        Yields:
            çŠ¶æ€æ›´æ–°å­—å…¸

        Note:
            å½“ Deep Agents SDK æœªå®‰è£…æ—¶ï¼Œä¸ä¼šè‡ªåŠ¨é™çº§åˆ°æ™®é€š LLM èŠå¤©ï¼Œ
            è€Œæ˜¯æŠ›å‡º ImportErrorï¼Œè®©è°ƒç”¨è€…å†³å®šå¦‚ä½•é™çº§ã€‚
        """
        self._ensure_agent()

        if self._agent is None:
            # Deep Agent ä¸å¯ç”¨ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©è°ƒç”¨è€…å¤„ç†é™çº§
            raise ImportError("Deep Agents SDK æœªå®‰è£…ï¼Œè¯·é™çº§åˆ° ReAct Agent")

        # æ„å»ºæ¶ˆæ¯
        if messages is None:
            messages = [HumanMessage(content=input_text)]

        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        formatted_messages = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                formatted_messages.append(
                    {"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                formatted_messages.append(
                    {"role": "assistant", "content": msg.content})
            else:
                formatted_messages.append(
                    {"role": "user", "content": str(msg.content)})

        try:
            iteration = 0
            # å¿«é€Ÿé€šé“ï¼šè·Ÿè¸ªæ˜¯å¦æ£€æµ‹åˆ°çœŸæ­£çš„å·¥å…·è°ƒç”¨
            has_real_tool_call = False

            # è¿½è¸ªå†å²æ¶ˆæ¯æ•°é‡ï¼Œç”¨äºåŒºåˆ†æ–°æ—§æ¶ˆæ¯
            # formatted_messages åŒ…å«å†å²æ¶ˆæ¯ + æ–°ç”¨æˆ·é—®é¢˜
            # å†å²æ¶ˆæ¯æ•°é‡ = æ€»æ•° - 1ï¼ˆæ–°ç”¨æˆ·é—®é¢˜ï¼‰
            history_message_count = len(
                formatted_messages) - 1 if formatted_messages else 0
            # è¿½è¸ªå·²å¤„ç†çš„æ¶ˆæ¯æ•°é‡
            processed_message_count = history_message_count

            logger.info(
                f"[DeepAgent] å¼€å§‹æµå¼æ‰§è¡Œï¼Œhistory_message_count={history_message_count}, formatted_messages={len(formatted_messages)}")

            # æµå¼æ‰§è¡Œ Agent
            async for event in self._agent.astream({"messages": formatted_messages}):
                iteration += 1
                logger.info(
                    f"[DeepAgent] Event #{iteration}: type={type(event).__name__}")

                # å¤„ç†ä¸åŒç±»å‹çš„ event
                # LangGraph å¯èƒ½è¿”å› dict æˆ– Command å¯¹è±¡ï¼ˆå¦‚ Overwriteï¼‰
                if isinstance(event, dict):
                    items = event.items()
                elif hasattr(event, 'items'):
                    items = event.items()
                else:
                    # å•ä¸ª Command å¯¹è±¡ï¼Œç›´æ¥å¤„ç†
                    logger.debug(
                        f"[DeepAgent] Event type: {type(event).__name__}")
                    content = self._extract_content_with_history(
                        event, processed_message_count)
                    # å¿«é€Ÿé€šé“ï¼šå¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¾“å‡ºå†…å®¹
                    if not has_real_tool_call:
                        yield {
                            "node": "agent",
                            "step_type": "stream_chunk",
                            "content": content,
                            "iteration": iteration,
                            "update": event
                        }
                        continue
                    step_data = {
                        "node": "agent",
                        "step_type": "thought",
                        "content": content,
                        "iteration": iteration,
                        "update": event
                    }
                    yield step_data
                    continue

                for node_name, state_update in items:
                    # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°åŸå§‹äº‹ä»¶æ•°æ®
                    logger.info(
                        f"[DeepAgent] Event: node={node_name}, update_type={type(state_update).__name__}")

                    # æ£€æµ‹æ˜¯å¦æœ‰çœŸæ­£çš„å·¥å…·è°ƒç”¨
                    tool_call_info = self._extract_tool_call(state_update)
                    if tool_call_info:
                        has_real_tool_call = True
                        logger.info(f"[DeepAgent] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {tool_call_info}")

                    # ä½¿ç”¨å¸¦å†å²è¿½è¸ªçš„å†…å®¹æå–
                    # æ³¨æ„ï¼šåˆå§‹ç”¨æˆ·æ¶ˆæ¯å·²ç»åŒ…å«åœ¨ formatted_messages ä¸­
                    # æ‰€ä»¥ä¸éœ€è¦å†æ¬¡è·³è¿‡ï¼Œä½¿ç”¨åŸå§‹çš„ history_message_count
                    content, new_msg_count = self._extract_content_with_history_count(
                        state_update, history_message_count)

                    logger.info(
                        f"[DeepAgent] æå–å†…å®¹: content_len={len(content) if content else 0}, new_msg_count={new_msg_count}, history_message_count={history_message_count}")

                    # ä¸è¦æ›´æ–° history_message_countï¼Œå®ƒåº”è¯¥ä¿æŒä¸å˜

                    # å¿«é€Ÿé€šé“é€»è¾‘ï¼š
                    # - å¦‚æœæ²¡æœ‰çœŸæ­£çš„å·¥å…·è°ƒç”¨ï¼Œä¸å‘é€ thought/tool_call æ­¥éª¤
                    # - ç›´æ¥å‘é€æµå¼å†…å®¹
                    if not has_real_tool_call:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥æµå¼è¾“å‡º
                        if content:
                            yield {
                                "node": node_name,
                                "step_type": "stream_chunk",
                                "content": content,
                                "iteration": iteration,
                                "update": state_update
                            }
                        continue

                    # æœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€è¯¦ç»†çš„æ€è€ƒæ­¥éª¤
                    # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ä¿¡æ¯å†³å®š step_type
                    if tool_call_info:
                        step_type = "tool_call"
                    else:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·ç»“æœï¼ˆToolMessageï¼‰
                        logger.info(
                            f"[DeepAgent] node={node_name}, å°è¯•æå– tool_result")
                        tool_result = self._extract_tool_result(
                            state_update, history_message_count)
                        logger.info(f"[DeepAgent] tool_result={tool_result}")
                        if tool_result:
                            # å‘é€ tool_result æ­¥éª¤
                            result_step = {
                                "node": node_name,
                                "step_type": "tool_result",
                                "content": tool_result.get("content", ""),
                                "iteration": iteration,
                                "update": state_update,
                                "tool_call": {
                                    "name": tool_result.get("name", "unknown"),
                                    "arguments": {},
                                    "result": tool_result.get("content", "")
                                }
                            }
                            if self.message_sender and conversation_id:
                                await self.message_sender.send_step(
                                    conversation_id=conversation_id,
                                    step_type="tool_result",
                                    content=tool_result.get("content", ""),
                                    tool_call=result_step["tool_call"],
                                    iteration=iteration
                                )
                            yield result_step
                            continue

                        # å·²ç»æœ‰å·¥å…·è°ƒç”¨ï¼Œä½†æ²¡æœ‰æ–°çš„å·¥å…·è°ƒç”¨
                        # è¯´æ˜æ˜¯å·¥å…·æ‰§è¡Œåçš„æœ€ç»ˆç­”æ¡ˆï¼Œä½œä¸ºæµå¼å†…å®¹å‘é€
                        # ä¸åœ¨æ€è€ƒè¿‡ç¨‹ä¸­æ˜¾ç¤ºï¼Œé¿å…é‡å¤
                        if content:
                            yield {
                                "node": node_name,
                                "step_type": "stream_chunk",
                                "content": content,
                                "iteration": iteration,
                                "update": state_update
                            }
                        continue

                    step_data = {
                        "node": node_name,
                        "step_type": step_type,
                        "content": content,
                        "iteration": iteration,
                        "update": state_update,
                        "tool_call": tool_call_info  # åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
                    }

                    # å‘é€æ­¥éª¤æ¶ˆæ¯
                    if self.message_sender and conversation_id:
                        await self.message_sender.send_step(
                            conversation_id=conversation_id,
                            step_type=step_type,
                            content=content,
                            tool_call=tool_call_info,  # ä¼ é€’å·¥å…·è°ƒç”¨ä¿¡æ¯
                            iteration=iteration
                        )

                    yield step_data

        except Exception as e:
            import traceback
            logger.error(f"[DeepAgent] æµå¼æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"[DeepAgent] Traceback:\n{traceback.format_exc()}")
            yield {
                "error": str(e),
                "step_type": "error",
                "content": f"æ‰§è¡Œå‡ºé”™: {str(e)}"
            }

    def _fallback_chat(
        self,
        input_text: str,
        messages: Optional[List] = None
    ) -> Dict[str, Any]:
        """
        é™çº§èŠå¤©æ–¹æ³•

        å½“ Deep Agent ä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨æ™®é€šèŠå¤©ã€‚

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            messages: å†å²æ¶ˆæ¯

        Returns:
            èŠå¤©ç»“æœ
        """
        from model_router import model_router

        # æ„å»ºæ¶ˆæ¯
        formatted_messages = []
        if messages:
            for msg in messages:
                if isinstance(msg, HumanMessage):
                    formatted_messages.append(
                        {"role": "user", "content": msg.content})
                elif isinstance(msg, AIMessage):
                    formatted_messages.append(
                        {"role": "assistant", "content": msg.content})

        formatted_messages.append({"role": "user", "content": input_text})

        try:
            response = model_router.chat(
                messages=formatted_messages,
                model_id=self.model_id,
                stream=False
            )

            return {
                "output": response,
                "steps": [AgentStep(
                    type="answer",
                    content=response,
                    tool_call=None
                )]
            }

        except Exception as e:
            logger.error(f"[DeepAgent] é™çº§èŠå¤©å¤±è´¥: {e}")
            return {
                "output": f"èŠå¤©å‡ºé”™: {str(e)}",
                "error": str(e)
            }

    async def _fallback_stream(
        self,
        input_text: str,
        messages: Optional[List] = None
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        é™çº§æµå¼èŠå¤©æ–¹æ³•

        å½“ Deep Agent ä¸å¯ç”¨æ—¶ï¼Œä½¿ç”¨æ™®é€šæµå¼èŠå¤©ã€‚

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            messages: å†å²æ¶ˆæ¯

        Yields:
            æµå¼å†…å®¹å—
        """
        from model_router import model_router

        # æ„å»ºæ¶ˆæ¯
        formatted_messages = []
        if messages:
            for msg in messages:
                if isinstance(msg, HumanMessage):
                    formatted_messages.append(
                        {"role": "user", "content": msg.content})
                elif isinstance(msg, AIMessage):
                    formatted_messages.append(
                        {"role": "assistant", "content": msg.content})

        formatted_messages.append({"role": "user", "content": input_text})

        try:
            full_content = ""

            async for chunk in model_router.chat_stream_async(
                messages=formatted_messages,
                model_id=self.model_id
            ):
                full_content += chunk

                yield {
                    "step_type": "stream_chunk",
                    "content": chunk,
                    "full_content": full_content
                }

            # æœ€ç»ˆç­”æ¡ˆ
            yield {
                "step_type": "answer",
                "content": full_content
            }

        except Exception as e:
            logger.error(f"[DeepAgent] é™çº§æµå¼èŠå¤©å¤±è´¥: {e}")
            yield {
                "error": str(e),
                "step_type": "error",
                "content": f"èŠå¤©å‡ºé”™: {str(e)}"
            }

    def _parse_step_type(self, node_name: str, state_update) -> str:
        """
        è§£ææ­¥éª¤ç±»å‹

        Args:
            node_name: èŠ‚ç‚¹åç§°
            state_update: çŠ¶æ€æ›´æ–°ï¼ˆå¯èƒ½æ˜¯ dict æˆ– LangGraph çš„ Command å¯¹è±¡ï¼‰

        Returns:
            æ­¥éª¤ç±»å‹å­—ç¬¦ä¸²
        """
        if "tool" in node_name.lower():
            return "tool_call"
        elif "agent" in node_name.lower():
            return "thought"
        elif "answer" in node_name.lower() or "final" in node_name.lower():
            return "answer"
        else:
            return "thought"

    def _extract_content(self, state_update) -> str:
        """
        æå–å†…å®¹ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

        æ³¨æ„ï¼šæ¨èä½¿ç”¨ _extract_content_with_history_count æ–¹æ³•ï¼Œ
        è¯¥æ–¹æ³•å¯ä»¥æ­£ç¡®åŒºåˆ†å†å²æ¶ˆæ¯å’Œæ–°æ¶ˆæ¯ã€‚
        """
        return self._extract_content_with_history(state_update, 0)

    def _extract_content_with_history(self, state_update, history_count: int) -> str:
        """
        æå–å†…å®¹ï¼Œè€ƒè™‘å†å²æ¶ˆæ¯æ•°é‡

        Args:
            state_update: çŠ¶æ€æ›´æ–°
            history_count: å†å²æ¶ˆæ¯æ•°é‡ï¼ˆåªæå–æ­¤æ•°é‡ä¹‹åçš„æ¶ˆæ¯ï¼‰

        Returns:
            å†…å®¹å­—ç¬¦ä¸²
        """
        content, _ = self._extract_content_with_history_count(
            state_update, history_count)
        return content

    def _extract_content_with_history_count(self, state_update, history_count: int) -> tuple:
        """
        æå–å†…å®¹å¹¶è¿”å›æ¶ˆæ¯æ•°é‡ï¼Œè€ƒè™‘å†å²æ¶ˆæ¯æ•°é‡

        æ³¨æ„ï¼šLangGraph æ¯ä¸ªäº‹ä»¶è¿”å›çš„æ¶ˆæ¯åˆ—è¡¨æ˜¯ç‹¬ç«‹çš„ï¼Œä¸æ˜¯ç´¯ç§¯çš„ã€‚
        history_count ä¸»è¦ç”¨äºæœ‰å†å²å¯¹è¯çš„åœºæ™¯ï¼Œè·³è¿‡å†å²æ¶ˆæ¯ã€‚

        Args:
            state_update: çŠ¶æ€æ›´æ–°ï¼ˆå¯èƒ½æ˜¯ dictã€list æˆ– LangGraph çš„ Command å¯¹è±¡ï¼‰
            history_count: å†å²æ¶ˆæ¯æ•°é‡ï¼ˆåªæå–æ­¤æ•°é‡ä¹‹åçš„æ¶ˆæ¯ï¼‰

        Returns:
            (å†…å®¹å­—ç¬¦ä¸², å½“å‰æ¶ˆæ¯æ•°é‡) å…ƒç»„
        """
        content = None
        current_count = history_count

        # å¤„ç† LangGraph çš„ Command å¯¹è±¡ï¼ˆå¦‚ Overwriteï¼‰
        if hasattr(state_update, '__class__') and state_update.__class__.__name__ in ['Overwrite', 'Command']:
            try:
                if hasattr(state_update, 'value'):
                    value = state_update.value
                    if isinstance(value, list) and value:
                        current_count = len(value)
                        # å¦‚æœæ¶ˆæ¯æ•°é‡å¤§äº history_countï¼Œè¯´æ˜æœ‰æ–°æ¶ˆæ¯
                        if current_count > history_count:
                            content = self._find_new_ai_content(
                                value, history_count)
                    elif hasattr(value, 'content'):
                        if self._is_ai_message(value):
                            content = value.content
                            current_count = history_count + 1
                return (str(content) if content else "", current_count)
            except Exception as e:
                logger.debug(f"[DeepAgent] å¤„ç† Overwrite å¯¹è±¡å¤±è´¥: {e}")
                return ("", current_count)

        # å¤„ç†å­—å…¸ç±»å‹
        if isinstance(state_update, dict):
            messages = state_update.get("messages", [])
            # messages å¯èƒ½æ˜¯ Overwrite å¯¹è±¡
            if messages and hasattr(messages, '__class__') and messages.__class__.__name__ == 'Overwrite':
                return self._extract_content_with_history_count(messages, history_count)

            if messages and isinstance(messages, list):
                current_count = len(messages)
                # å¦‚æœæ¶ˆæ¯æ•°é‡å¤§äº history_countï¼Œè¯´æ˜æœ‰æ–°æ¶ˆæ¯
                if current_count > history_count:
                    content = self._find_new_ai_content(
                        messages, history_count)
                else:
                    # æ¶ˆæ¯æ•°é‡æ²¡æœ‰å¢åŠ ï¼Œå¯èƒ½æ˜¯æ–°äº‹ä»¶ï¼Œç›´æ¥æ‰¾ AI æ¶ˆæ¯
                    content = self._find_ai_content_simple(messages)

        # å¤„ç†åˆ—è¡¨ç±»å‹
        if isinstance(state_update, list):
            current_count = len(state_update)
            if current_count > history_count:
                content = self._find_new_ai_content(
                    state_update, history_count)
            else:
                content = self._find_ai_content_simple(state_update)

        return (str(content) if content else "", current_count)

    def _find_ai_content_simple(self, messages: list) -> Optional[str]:
        """
        ç®€å•åœ°ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–æœ€åä¸€ä¸ª AI æ¶ˆæ¯çš„å†…å®¹

        ç”¨äºå¤„ç†æ¶ˆæ¯æ•°é‡æ²¡æœ‰å¢åŠ çš„æƒ…å†µï¼ˆæ–°äº‹ä»¶ï¼‰ã€‚

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            å†…å®¹å­—ç¬¦ä¸²æˆ– None
        """
        if not messages:
            return None

        # ä»åå¾€å‰æ‰¾ç¬¬ä¸€ä¸ª AI æ¶ˆæ¯
        for msg in reversed(messages):
            if self._is_ai_message(msg):
                msg_content = None
                if hasattr(msg, 'content'):
                    msg_content = msg.content
                elif isinstance(msg, dict):
                    msg_content = msg.get("content")

                if msg_content:
                    return str(msg_content)

        return None

    def _find_new_ai_content(self, messages: list, history_count: int) -> Optional[str]:
        """
        ä»æ–°æ¶ˆæ¯ä¸­æå– AI æ¶ˆæ¯å†…å®¹

        åªæŸ¥æ‰¾ history_count ä¹‹åçš„æ¶ˆæ¯ï¼Œé¿å…è¿”å›å†å²æ¶ˆæ¯å†…å®¹ã€‚

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            history_count: å†å²æ¶ˆæ¯æ•°é‡

        Returns:
            å†…å®¹å­—ç¬¦ä¸²æˆ– None
        """
        if not messages:
            logger.info(f"[DeepAgent] _find_new_ai_content: messages ä¸ºç©º")
            return None

        # åªçœ‹æ–°æ¶ˆæ¯éƒ¨åˆ†ï¼ˆä» history_count å¼€å§‹ï¼‰
        new_messages = messages[history_count:]

        logger.info(
            f"[DeepAgent] _find_new_ai_content: total_msgs={len(messages)}, history_count={history_count}, new_msgs={len(new_messages)}")

        if not new_messages:
            logger.info(f"[DeepAgent] _find_new_ai_content: new_messages ä¸ºç©º")
            return None

        # ä»æ–°æ¶ˆæ¯ä¸­æ‰¾æœ€åä¸€ä¸ª AI æ¶ˆæ¯
        for msg in reversed(new_messages):
            msg_type = getattr(msg, 'type', None) if hasattr(
                msg, 'type') else None
            msg_class = msg.__class__.__name__ if hasattr(
                msg, '__class__') else 'unknown'
            is_ai = self._is_ai_message(msg)
            logger.info(
                f"[DeepAgent] _find_new_ai_content: msg_type={msg_type}, class={msg_class}, is_ai={is_ai}")

            if is_ai:
                msg_content = None
                if hasattr(msg, 'content'):
                    msg_content = msg.content
                elif isinstance(msg, dict):
                    msg_content = msg.get("content")

                if msg_content:
                    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›è¿™ä¸ªå†…å®¹ï¼ˆå·¥å…·è°ƒç”¨çš„æ€è€ƒï¼‰
                    # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä¹Ÿè¿”å›å†…å®¹ï¼ˆæœ€ç»ˆç­”æ¡ˆï¼‰
                    logger.info(
                        f"[DeepAgent] _find_new_ai_content: æ‰¾åˆ° AI æ¶ˆæ¯ï¼Œcontent_len={len(str(msg_content))}")
                    return str(msg_content)

        logger.info(f"[DeepAgent] _find_new_ai_content: æ²¡æœ‰æ‰¾åˆ° AI æ¶ˆæ¯")
        return None

    def _has_tool_calls(self, message) -> bool:
        """
        æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨

        Args:
            message: LangChain æ¶ˆæ¯å¯¹è±¡

        Returns:
            æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        """
        # æ£€æŸ¥ tool_calls å±æ€§
        if hasattr(message, 'tool_calls') and message.tool_calls:
            return True
        # æ£€æŸ¥ additional_kwargs ä¸­çš„ tool_calls
        if hasattr(message, 'additional_kwargs'):
            tool_calls = message.additional_kwargs.get('tool_calls', [])
            if tool_calls:
                return True
        return False

    def _is_ai_message(self, message) -> bool:
        """
        æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦æ˜¯ AI æ¶ˆæ¯ï¼ˆéœ€è¦æµå¼è¾“å‡ºç»™ç”¨æˆ·çš„æ¶ˆæ¯ï¼‰

        æ³¨æ„ï¼šToolMessage æ˜¯å·¥å…·è¿”å›ç»“æœï¼Œä¸åº”è¯¥ä½œä¸ºæµå¼å†…å®¹è¾“å‡ºç»™ç”¨æˆ·ã€‚
        å·¥å…·ç»“æœåº”è¯¥é€šè¿‡ tool_result æ­¥éª¤å‘é€åˆ°æ€è€ƒè¿‡ç¨‹ã€‚

        Args:
            message: LangChain æ¶ˆæ¯å¯¹è±¡

        Returns:
            æ˜¯å¦æ˜¯ AI æ¶ˆæ¯
        """
        # æ£€æŸ¥æ¶ˆæ¯ç±»å‹
        if hasattr(message, 'type'):
            # type ä¸º 'human' è¡¨ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼Œè·³è¿‡
            if message.type == 'human':
                return False
            # type ä¸º 'tool' è¡¨ç¤ºå·¥å…·æ¶ˆæ¯ï¼Œä¸åº”è¯¥æµå¼è¾“å‡º
            if message.type == 'tool':
                return False
            # type ä¸º 'ai' è¡¨ç¤º AI æ¶ˆæ¯
            if message.type == 'ai':
                return True

        # æ£€æŸ¥ç±»å
        if hasattr(message, '__class__'):
            class_name = message.__class__.__name__
            # HumanMessage æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œè·³è¿‡
            if class_name == 'HumanMessage':
                return False
            # ToolMessage æ˜¯å·¥å…·è¿”å›ç»“æœï¼Œä¸åº”è¯¥æµå¼è¾“å‡ºç»™ç”¨æˆ·
            if class_name == 'ToolMessage':
                return False
            # AIMessage æ˜¯ AI æ¶ˆæ¯ï¼Œéœ€è¦æµå¼è¾“å‡º
            if class_name == 'AIMessage':
                return True

        # å­—å…¸ç±»å‹æ£€æŸ¥ role
        if isinstance(message, dict):
            role = message.get('role', '')
            if role == 'user':
                return False
            # tool è§’è‰²æ˜¯å·¥å…·æ¶ˆæ¯ï¼Œä¸åº”è¯¥æµå¼è¾“å‡º
            if role == 'tool':
                return False
            if role in ['assistant', 'ai']:
                return True

        # é»˜è®¤æƒ…å†µï¼Œæ— æ³•åˆ¤æ–­ï¼Œä¿å®ˆå¤„ç†è¿”å› False
        return False

    def _extract_tool_call(self, state_update) -> Optional[Dict]:
        """
        æå–å·¥å…·è°ƒç”¨ä¿¡æ¯

        æ£€æµ‹ LLM æ˜¯å¦çœŸæ­£è°ƒç”¨äº†å·¥å…·ã€‚

        Args:
            state_update: çŠ¶æ€æ›´æ–°ï¼ˆå¯èƒ½æ˜¯ dictã€list æˆ– LangGraph çš„ Command å¯¹è±¡ï¼‰

        Returns:
            å·¥å…·è°ƒç”¨ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨è¿”å› None
            æ ¼å¼: {"name": "tool_name", "arguments": {...}}
        """
        # å¤„ç† LangGraph çš„ Command å¯¹è±¡ï¼ˆå¦‚ Overwriteï¼‰
        if hasattr(state_update, '__class__') and state_update.__class__.__name__ in ['Overwrite', 'Command']:
            try:
                if hasattr(state_update, 'value'):
                    value = state_update.value
                    if isinstance(value, list) and value:
                        last_item = value[-1]
                        return self._extract_tool_call_from_message(last_item)
                    elif hasattr(value, 'tool_calls'):
                        return self._extract_tool_call_from_message(value)
            except Exception as e:
                logger.debug(f"[DeepAgent] å¤„ç† Overwrite å¯¹è±¡å¤±è´¥: {e}")
            return None

        # å¤„ç†å­—å…¸ç±»å‹
        if isinstance(state_update, dict):
            messages = state_update.get("messages", [])
            if messages and hasattr(messages, '__class__') and messages.__class__.__name__ == 'Overwrite':
                return self._extract_tool_call(messages)  # é€’å½’å¤„ç†

            if messages:
                last_msg = messages[-1] if isinstance(
                    messages, list) else messages
                return self._extract_tool_call_from_message(last_msg)

        # å¤„ç†åˆ—è¡¨ç±»å‹
        if isinstance(state_update, list):
            if state_update:
                last_item = state_update[-1]
                return self._extract_tool_call_from_message(last_item)

        return None

    def _extract_tool_call_from_message(self, message) -> Optional[Dict]:
        """
        ä»æ¶ˆæ¯å¯¹è±¡ä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯

        Args:
            message: LangChain æ¶ˆæ¯å¯¹è±¡

        Returns:
            å·¥å…·è°ƒç”¨ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨è¿”å› None
        """
        # æ£€æŸ¥ AIMessage çš„ tool_calls å±æ€§
        if hasattr(message, 'tool_calls') and message.tool_calls:
            # tool_calls æ˜¯ä¸€ä¸ªåˆ—è¡¨
            first_tool_call = message.tool_calls[0]
            if isinstance(first_tool_call, dict):
                tool_info = {
                    "name": first_tool_call.get("name", "unknown"),
                    "arguments": first_tool_call.get("args", {})
                }
            elif hasattr(first_tool_call, 'name'):
                tool_info = {
                    "name": first_tool_call.name,
                    "arguments": getattr(first_tool_call, 'args', {})
                }
            else:
                return None

            # å¦‚æœæ˜¯ file_read å·¥å…·ï¼Œä¿®æ­£æ–‡ä»¶è·¯å¾„
            if tool_info["name"] == "file_read" and "file_path" in tool_info["arguments"]:
                original_path = tool_info["arguments"]["file_path"]
                corrected_path = DeepAgentWrapper.get_correct_file_path(
                    original_path)
                if corrected_path != original_path:
                    logger.info(
                        f"[DeepAgent] æå–æ—¶è·¯å¾„ä¿®æ­£: {original_path} -> {corrected_path}")
                    tool_info["arguments"]["file_path"] = corrected_path

            return tool_info

        # æ£€æŸ¥ additional_kwargs ä¸­çš„ tool_callsï¼ˆOpenAI æ ¼å¼ï¼‰
        if hasattr(message, 'additional_kwargs'):
            tool_calls = message.additional_kwargs.get('tool_calls', [])
            if tool_calls:
                first_tool_call = tool_calls[0]
                if isinstance(first_tool_call, dict):
                    function = first_tool_call.get('function', {})
                    tool_info = {
                        "name": function.get('name', 'unknown'),
                        "arguments": function.get('arguments', {})
                    }

                    # å¦‚æœæ˜¯ file_read å·¥å…·ï¼Œä¿®æ­£æ–‡ä»¶è·¯å¾„
                    if tool_info["name"] == "file_read" and "file_path" in tool_info["arguments"]:
                        original_path = tool_info["arguments"]["file_path"]
                        corrected_path = DeepAgentWrapper.get_correct_file_path(
                            original_path)
                        if corrected_path != original_path:
                            logger.info(
                                f"[DeepAgent] æå–æ—¶è·¯å¾„ä¿®æ­£: {original_path} -> {corrected_path}")
                            tool_info["arguments"]["file_path"] = corrected_path

                    return tool_info

        return None

    def _extract_tool_result(self, state_update, history_count: int = 0) -> Optional[Dict]:
        """
        æå–å·¥å…·ç»“æœä¿¡æ¯ï¼ˆToolMessageï¼‰

        æ£€æµ‹æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œç»“æœã€‚

        Args:
            state_update: çŠ¶æ€æ›´æ–°
            history_count: å†å²æ¶ˆæ¯æ•°é‡

        Returns:
            å·¥å…·ç»“æœä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« name å’Œ contentï¼›å¦‚æœæ²¡æœ‰è¿”å› None
        """
        logger.info(
            f"[DeepAgent] _extract_tool_result: state_update_type={type(state_update).__name__}")

        # å¤„ç† LangGraph çš„ Command å¯¹è±¡ï¼ˆå¦‚ Overwriteï¼‰
        if hasattr(state_update, '__class__') and state_update.__class__.__name__ in ['Overwrite', 'Command']:
            try:
                if hasattr(state_update, 'value'):
                    value = state_update.value
                    logger.debug(
                        f"[DeepAgent] _extract_tool_result: Overwrite value type={type(value).__name__}, len={len(value) if isinstance(value, list) else 'N/A'}")
                    if isinstance(value, list) and value:
                        # æŸ¥æ‰¾ ToolMessage
                        for msg in reversed(value[history_count:] if history_count else value):
                            result = self._extract_tool_result_from_message(
                                msg)
                            if result:
                                return result
            except Exception as e:
                logger.debug(f"[DeepAgent] å¤„ç† Overwrite å¯¹è±¡å¤±è´¥: {e}")
            return None

        # å¤„ç†å­—å…¸ç±»å‹
        if isinstance(state_update, dict):
            messages = state_update.get("messages", [])
            logger.info(
                f"[DeepAgent] _extract_tool_result: dict keys={list(state_update.keys())}, messages type={type(messages).__name__}, len={len(messages) if isinstance(messages, list) else 'N/A'}")
            if messages and hasattr(messages, '__class__') and messages.__class__.__name__ == 'Overwrite':
                return self._extract_tool_result(messages, history_count)

            if messages and isinstance(messages, list):
                # æŸ¥æ‰¾æ–°æ¶ˆæ¯ä¸­çš„ ToolMessage
                for msg in reversed(messages[history_count:] if history_count else messages):
                    msg_type = getattr(msg, 'type', None) if hasattr(
                        msg, 'type') else None
                    msg_class = msg.__class__.__name__ if hasattr(
                        msg, '__class__') else 'unknown'
                    logger.info(
                        f"[DeepAgent] _extract_tool_result: æ£€æŸ¥æ¶ˆæ¯ type={msg_type}, class={msg_class}")
                    result = self._extract_tool_result_from_message(msg)
                    if result:
                        return result

        # å¤„ç†åˆ—è¡¨ç±»å‹
        if isinstance(state_update, list):
            logger.debug(
                f"[DeepAgent] _extract_tool_result: list len={len(state_update)}")
            for msg in reversed(state_update[history_count:] if history_count else state_update):
                result = self._extract_tool_result_from_message(msg)
                if result:
                    return result

        return None

    def _extract_tool_result_from_message(self, message) -> Optional[Dict]:
        """
        ä»æ¶ˆæ¯å¯¹è±¡ä¸­æå–å·¥å…·ç»“æœä¿¡æ¯

        Args:
            message: LangChain æ¶ˆæ¯å¯¹è±¡

        Returns:
            å·¥å…·ç»“æœä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« name å’Œ contentï¼›å¦‚æœä¸æ˜¯ ToolMessage è¿”å› None
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯ ToolMessage
        is_tool = False
        tool_name = None
        content = None

        # é€šè¿‡ type å±æ€§æ£€æŸ¥
        if hasattr(message, 'type'):
            if message.type == 'tool':
                is_tool = True
                # ToolMessage æœ‰ name å±æ€§è¡¨ç¤ºå·¥å…·åç§°
                if hasattr(message, 'name'):
                    tool_name = message.name
                logger.debug(f"[DeepAgent] æ£€æµ‹åˆ° tool ç±»å‹æ¶ˆæ¯: name={tool_name}")

        # é€šè¿‡ç±»åæ£€æŸ¥
        if hasattr(message, '__class__'):
            class_name = message.__class__.__name__
            if class_name == 'ToolMessage':
                is_tool = True
                # ToolMessage æœ‰ name å±æ€§è¡¨ç¤ºå·¥å…·åç§°
                if hasattr(message, 'name'):
                    tool_name = message.name
                logger.debug(
                    f"[DeepAgent] æ£€æµ‹åˆ° ToolMessage ç±»: name={tool_name}")

        # é€šè¿‡å­—å…¸ role æ£€æŸ¥
        if isinstance(message, dict):
            if message.get('role') == 'tool':
                is_tool = True
                tool_name = message.get('name')
                logger.debug(f"[DeepAgent] æ£€æµ‹åˆ° tool role å­—å…¸: name={tool_name}")

        if not is_tool:
            return None

        # æå–å†…å®¹
        if hasattr(message, 'content'):
            content = str(message.content)
        elif isinstance(message, dict):
            content = str(message.get('content', ''))

        if content is None:
            return None

        logger.info(
            f"[DeepAgent] æå–åˆ°å·¥å…·ç»“æœ: name={tool_name}, content_len={len(content)}")

        return {
            "name": tool_name or "unknown",
            "content": content
        }

    def _extract_steps(self, result: Dict) -> List[AgentStep]:
        """
        ä»æ‰§è¡Œç»“æœä¸­æå–æ­¥éª¤åˆ—è¡¨

        Args:
            result: Agent æ‰§è¡Œç»“æœ

        Returns:
            æ­¥éª¤åˆ—è¡¨
        """
        steps = []

        messages = result.get("messages", [])
        for msg in messages:
            content = msg.content if hasattr(msg, "content") else str(msg)
            msg_type = msg.type if hasattr(msg, "type") else "unknown"

            step_type = "thought"
            if msg_type == "ai":
                step_type = "answer"
            elif msg_type == "tool":
                step_type = "tool_result"

            steps.append(AgentStep(
                type=step_type,
                content=content,
                tool_call=None
            ))

        return steps


# ==================== å·¥å‚å‡½æ•° ====================

def create_deep_agent(
    model_id: Optional[int] = None,
    tools: Optional[List[BaseTool]] = None,
    system_prompt: Optional[str] = None,
    message_sender: Optional[MessageSender] = None
) -> DeepAgentWrapper:
    """
    åˆ›å»º Deep Agent å®ä¾‹

    Args:
        model_id: æ¨¡å‹é…ç½® ID
        tools: è‡ªå®šä¹‰å·¥å…·åˆ—è¡¨
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        message_sender: æ¶ˆæ¯å‘é€å™¨

    Returns:
        DeepAgentWrapper å®ä¾‹
    """
    return DeepAgentWrapper(
        model_id=model_id,
        tools=tools,
        system_prompt=system_prompt,
        message_sender=message_sender
    )
